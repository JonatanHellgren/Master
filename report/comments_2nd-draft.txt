Det finns lite olika standardsätt att redovisa citeringar och referenser, och du bör hålla dig till något av dessa; jag rekommenderar APA 6th (https://libguides.library.usyd.edu.au/c.php?g=508212&p=3476096).

 

”They later describe four different approaches…”. Om det skall vara någon mening med att säga detta behöver du också räkna upp vilka dessa angreppssätt är.

 

”…doing the right thing.” Detta är otydligt. Att göra det rätta för vad? Moraliskt rätt, eller instrumentellt rätt för att uppnå givna mål?

 

”Reinforcement Learning is the field of AI that creates intelligent agents”. Det här känns inte rätt. Även om det förekommer spekulationer om att RL är unikt lämpat för denna uppgift (https://www.sciencedirect.com/science/article/pii/S0004370221000862) så har knappast RL något monopol på den. Säg istället något om hur RL fungerar.

 

”were not to apply” -> ”were not only to apply”. (Narrow AI fanns med från början.)

 

Lee Sedol var inte världsmästare.

 

”Recently, DeepMind has released…”. Med tanke på hur snabbt AI-utvecklingen går nu så tycker jag inte att man bör kalla 2017 ”recently”.

 

”intelligence might not have been selected for by evolution”. Saken är komplicerad såklart, men ditt påstående är väldigt konstigt. Om du ändå vill hävda detta påstående så visa mig gärna den passage av Shane Legg du bygger det på.

 

I samband med ”substance dependence” behöver vi skilja mellan intelligens och medvetande. Rörande medvetande (som är ett väldigt perifert begrepp i förhållande till detta exjobb) finns en levande debatt om substance dependence, men rörande intelligens finns knappast längre någon vettig möjlighet att försvara idén om substance dependence.

 

”An AGI breakthrough is probably necessary…”. Denna mening later som nonsens, men kanske fattas det bara en negation?

 

”If this iterative process keeps going, it will create an intelligence explosion…”. Detta är förhastat. Såvitt vi vet finns inga garantier för att processen går så fort att den förtjänar benämnas explosion. Ett annat möjligt scenario är att effekter av typen ”alla lågt hängande frukter har redan plockats” skapar en inbromsning. Yudkowsky (2013) behandlar denna problematik ingående, eller se Kapitel 4 i Tänkande maskiner för en mer summarisk behandling.

 

”The AI systems of today work by giving the agent…”. Språkligt fungerar det så att ”giving” behöver ett subjekt (who is giving?), och att läsaren söker i meningen efter ett subjekt, och då landar på ”The AI systems”, men det är knappast så du menar, eller hur?

 

”The orthogonality thesis […] states that the intelligence of an AI is logically independent…”. Det här är lite för kategoriskt formulerat eftersom det faktiskt finns motexempel; Bostrom tar själv upp ett sådant, och jag behandlar frågan i https://www.emerald.com/insight/content/doi/10.1108/FS-04-2018-0039/full/html

 

Det problematiska med jämförelserna med ”a bee” och andra organismer bör nog understrykas – intelligens är inte endimensionellt!

 

”the state-of-the-art language generator”. Eftersom du nämnt AlphaStar och andra programvaror vid namn bör du nog göra det även för de NLP:er som här avses.

 

Innan du kommer in på ”for the median of 2052” etc bör du nog förklara att Cotras analys landar i en (kraftigt utspridd) bayesiansk sannolikhetsfördelning; innan det sagts betyder ord som ”median” ingenting.

 

”possibly even existential…”. Jag ser att du använder ordet ”existential” här och flera gånger framöver, men definierar du det någonsin? Jag tror inte att man kan förvänta sig att den typiske läsaren vet vad det betyder i dessa sammanhang.

 

Understryk att det är i machine learning-sammanhang (och inte nödvändigtvis i AI mer generellt) som distinktionen inner vs outer alignment är meningsfull. De begrepp ”base optimizer” och ”mesa optimizer” du använder behöver i sin tur förklaras, och jag tror att det vore bra att göra det lite mer konkret: i vilka sammanhang uppstår en mesa optimizer?

 

”a seemingly stupid task…”. Du använder ordet ”stupid” i liknande mening även någon gång tidigare i texten, och även om du båda gångerna distanserar dig från begreppet genom ord som ”seemingly” så tycker jag att ”stupid task” är ett begrepp som du bör använda maximalt en gång (och då med tydligt avståndstagande) eftersom det bryter mot det tänkande som ortogonalitetstesen anbefaller: mål och intelligens är ortogonala dimensioner, så att kalla ett mål ointelligent blir ett kategorifel. Säg t.ex. ”undesirable” istället.

 

Att kalla Toby Ord ”a philosopher that focuses on existential risk” (bara för att hans senaste bok gör det) är att kraftigt undervärdera bredden i hans forskning.

 

”In recent years the field […] has seen a substantial increase”. Ja, men i sammanhanget bör det nog understrykas att området fortfarande är litet både i absoluta tal och i jämförelse med AI-området som helhet.

 

”To achieve a more general approach constraints have been included in the reward function to penalize negative impact.” Jag tänker på ordet “negative” här. Strängt taget är det väl bara sådan impact vi behöver undvika, men att klassificera alla tänkbara effekter i universum med avseende på dikotomin positiv/negativ är väl ett så gigantiskt projekt att det framstår som närmast hopplöst. Och just av detta skäl är det väl så att mycket av litteraturen (i synnerhet Armstrong-Levinstein) släpper ”negative” här och bestämmer sig för att mer generellt bestraffa ”impact”?
