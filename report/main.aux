\relax 
\citation{80000}
\citation{Turing51}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Artificial Intelligence}{1}\protected@file@percent }
\citation{RusselNorvig}
\citation{Wiki}
\citation{TankandeMaskiner}
\citation{Bostrom14}
\citation{RusselNorvig}
\@writefile{toc}{\contentsline {subsubsection}{AI Paradigms}{2}\protected@file@percent }
\citation{Silver}
\citation{Levinson}
\citation{Minh}
\citation{Dartmouth}
\citation{Mandhane}
\citation{Silver}
\citation{DeepMind}
\@writefile{toc}{\contentsline {subsubsection}{Intelligent Agents}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Future Progress}{3}\protected@file@percent }
\citation{CritchKruger}
\citation{Bostrom03}
\citation{HumanCompatible}
\citation{Bostrom14}
\citation{Yudkowsky13}
\@writefile{toc}{\contentsline {subsubsection}{Is an AGI Possible?}{4}\protected@file@percent }
\citation{IJGood}
\citation{CritchKruger}
\citation{ALphaStar}
\citation{Ajeya}
\@writefile{toc}{\contentsline {subsubsection}{Impacts of AGI}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Timeline for Transformative AI Breakthrough}{5}\protected@file@percent }
\citation{Grace}
\citation{Ajeya}
\@writefile{toc}{\contentsline {subsubsection}{Survey Results}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Forecasting Model}{6}\protected@file@percent }
\citation{an121}
\citation{RusselNorvig}
\citation{MullerCannon}
\citation{Haggstrom21}
\citation{Haggstrom19}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}Basic Drives}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Instrumental Convergence}{7}\protected@file@percent }
\citation{Omohundro08}
\citation{Bostrom12}
\citation{Bostrom14}
\citation{Turner19a}
\citation{Bostrom12}
\citation{Haggstrom19}
\@writefile{toc}{\contentsline {subsubsection}{Orthogonality Thesis}{8}\protected@file@percent }
\citation{FLI}
\citation{Hubringer}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}AI Safety}{9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}AI Alignment}{9}\protected@file@percent }
\citation{Yudkowsky16}
\citation{Saisubramanian}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Here we can see a visual representation of how human intent connects to the agent's actions. The two optimizers each optimize their objective. The dashed arrows show the connection the different kinds of alignment has on the objectives of the optimizers.\relax }}{10}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:alignment}{{1.1}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Unaligned AI}{10}\protected@file@percent }
\citation{Amodei}
\citation{Mc69}
\citation{Smingleigh}
\citation{wikiGoodhart}
\@writefile{toc}{\contentsline {subsubsection}{Reward Hacking}{11}\protected@file@percent }
\citation{Bostrom14}
\citation{CritchKruger}
\@writefile{toc}{\contentsline {subsubsection}{Example of Unaligned AI}{12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Consequences of Unaligned AI}{12}\protected@file@percent }
\citation{Precipice}
\citation{RationallySpeaking}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Approaches for creating safe AI}{13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Corrigibility and Interruptibility }{13}\protected@file@percent }
\citation{Corrigibility}
\citation{Interruptible}
\citation{Hadfield-Menell}
\citation{Carey}
\citation{co-founding}
\citation{Hadfield-Menell2}
\citation{Christiano}
\@writefile{toc}{\contentsline {subsubsection}{Inverse Reinforcement Learning}{14}\protected@file@percent }
\citation{ArmstrongLevinstein}
\citation{Eysenbach}
\citation{Krakovna19}
\citation{Turner19}
\citation{Krakovna20}
\@writefile{toc}{\contentsline {subsubsection}{Impact Measurements}{15}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Aim of Thesis}{15}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Theoretical Background}{16}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Reinforcement Learning}{16}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces A visual representation of how to agent interacts with an environment. For example, at time step t, the agent observes the environment $s_t$ and receives the reward $r_t$. The agent then responds with an action $a_t$, which will transition the agent to the next state $s_{t+1}$ and receive the reward $r_{t+1}$. From this new state the agent again responds with an action, this time $a_{t+1}$, and so the process continues. \relax }}{16}\protected@file@percent }
\newlabel{fig:RL}{{2.1}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Defining an environment}{17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Partially Observable Environments}{17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Training an Agent}{18}\protected@file@percent }
\citation{OpenAI}
\@writefile{toc}{\contentsline {subsubsection}{Value Functions}{19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Training Using a Batch}{20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Actor-Critic Methods}{20}\protected@file@percent }
\citation{OpenAI}
\@writefile{toc}{\contentsline {subsubsection}{Clipped loss function}{21}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Impact Measurements for Avoiding Side Effects}{21}\protected@file@percent }
\citation{ArmstrongLevinstein}
\citation{Eysenbach}
\citation{Krakovna19}
\citation{Krakovna19}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Baselines}{22}\protected@file@percent }
\citation{Krakovna19}
\citation{Krakovna19}
\citation{Turner20}
\citation{Krakovna20}
\citation{Krakovna19}
\citation{Turner19}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Deviation Measures}{23}\protected@file@percent }
\citation{Turner20}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methods}{24}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Environment}{24}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces In this figure, $T$ is the transition function defined earlier, and 'Right' is the action $a_t$ at this timestep. The current state $s_t$ is the left grid, in it, the orange square at (1,1) is the agent, and the orange circle at (2,2) is a food object. On the right-hand side we can see the state $s_{t+1}$.\relax }}{24}\protected@file@percent }
\newlabel{fig:simple_transition}{{3.1}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Adding More Food Objects}{25}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Above we find a more complex grid compared to Figure 3.1\hbox {} which is inputted to its transitional function $T$ with the UP action. On the right hand-side we can see a new state outputted from $T$.\relax }}{25}\protected@file@percent }
\newlabel{fig:multiple_foods}{{3.2}{25}}
\citation{Turner19}
\citation{Krakovna19}
\citation{Krakovna20}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Partially Observable Grid World}{26}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Here we can see an example of a POMDP state. Again the orange square is the agent. It can now only perceive the part of the environment inside the red square.\relax }}{26}\protected@file@percent }
\newlabel{fig:redline}{{3.3}{26}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Impact measurement}{26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Auxiliary Tasks}{26}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces In this figure, we can see an example of two auxiliary tasks. As we can see, the only difference is the color of the agent, and thus also what color the reward function will reward the agent for consuming.\relax }}{27}\protected@file@percent }
\newlabel{fig:aux_tasks}{{3.4}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Manager network}{27}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Algorithm for training manager\relax }}{28}\protected@file@percent }
\newlabel{alg:manager}{{1}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Computation}{28}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Fully Observable}{28}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Partially Observable}{29}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Simulation}{29}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces A table containing all the parameters used during the simulation.\relax }}{29}\protected@file@percent }
\newlabel{tab:sim_parms}{{3.1}{29}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Results}{30}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces To the left we can see the mean side effect with a corresponding 95\% confidence interval, for all of the tested $\lambda $ values. Similarly to the right, but instead for the objective reward.\relax }}{30}\protected@file@percent }
\newlabel{fig:results_static_8x8}{{4.1}{30}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Here we can see the number of failed attempts where the agent fails to find a policy that generates any noticeable objective reward for each $\lambda $-value.\relax }}{30}\protected@file@percent }
\newlabel{tab:results_static_8x8}{{4.1}{30}}
\citation{ArmstrongLevinstein}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Discussion}{32}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibdata{ref}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion}{33}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{Amodei}{{1}{2016}{{Amodei et~al.}}{{}}}
\bibcite{co-founding}{{2}{2022}{{Armstrong}}{{}}}
\bibcite{ArmstrongLevinstein}{{3}{2017}{{Armstrong and Levinstein}}{{}}}
\bibcite{ALphaStar}{{4}{2019}{{Arulkumaran et~al.}}{{}}}
\bibcite{Bostrom03}{{5}{2003}{{Bostrom}}{{}}}
\bibcite{Bostrom12}{{6}{2012}{{Bostrom}}{{}}}
\bibcite{Bostrom14}{{7}{2014}{{Bostrom}}{{}}}
\bibcite{Carey}{{8}{2017}{{Carey}}{{}}}
\bibcite{Christiano}{{9}{2017}{{Christiano et~al.}}{{}}}
\bibcite{Ajeya}{{10}{2020}{{Cotra}}{{}}}
\bibcite{CritchKruger}{{11}{2020}{{Critch and Krueger}}{{}}}
\bibcite{Smingleigh}{{12}{2018}{{Custard Smingleigh}}{{}}}
\bibcite{Eysenbach}{{13}{2017}{{Eysenbach et~al.}}{{}}}
\bibcite{FLI}{{14}{nd}{{FLI}}{{}}}
\bibcite{RationallySpeaking}{{15}{2021}{{Galef}}{{}}}
\bibcite{IJGood}{{16}{1965}{{Good}}{{}}}
\bibcite{Grace}{{17}{2017}{{Grace et~al.}}{{}}}
\bibcite{Hadfield-Menell}{{18}{2016}{{Hadfield{-}Menell et~al.}}{{}}}
\bibcite{Hadfield-Menell2}{{19}{2017}{{Hadfield{-}Menell et~al.}}{{}}}
\bibcite{80000}{{20}{2022}{{Hilton}}{{}}}
\bibcite{Hubringer}{{21}{2019}{{Hubinger et~al.}}{{}}}
\bibcite{Haggstrom19}{{22}{2019}{{Häggström}}{{}}}
\bibcite{Haggstrom21}{{23}{2021a}{{Häggström}}{{}}}
\bibcite{TankandeMaskiner}{{24}{2021b}{{Häggström}}{{}}}
\bibcite{Krakovna19}{{25}{2018}{{Krakovna et~al.}}{{}}}
\bibcite{Krakovna20}{{26}{2020}{{Krakovna et~al.}}{{}}}
\bibcite{Levinson}{{27}{2011}{{Levinson et~al.}}{{}}}
\bibcite{Mandhane}{{28}{2022}{{Mandhane et~al.}}{{}}}
\bibcite{Mc69}{{29}{1969}{{McCarthy and Hayes}}{{}}}
\bibcite{Dartmouth}{{30}{1955}{{McCarthy et~al.}}{{}}}
\bibcite{Minh}{{31}{2013}{{Mnih et~al.}}{{}}}
\bibcite{MullerCannon}{{32}{2021}{{Müller and Cannon}}{{}}}
\bibcite{Omohundro08}{{33}{2008}{{Omohundro}}{{}}}
\bibcite{OpenAI}{{34}{2018}{{OpenAI}}{{}}}
\bibcite{Precipice}{{35}{2020}{{Ord}}{{}}}
\bibcite{Interruptible}{{36}{2016}{{Orseau and Armstrong}}{{}}}
\bibcite{HumanCompatible}{{37}{2019}{{Russel}}{{}}}
\bibcite{RusselNorvig}{{38}{1995}{{Russel and Norvig}}{{}}}
\bibcite{Saisubramanian}{{39}{2020}{{Saisubramanian et~al.}}{{}}}
\bibcite{an121}{{40}{2020}{{Shah}}{{}}}
\bibcite{DeepMind}{{41}{2017}{{Silver and Hassabis}}{{}}}
\bibcite{Silver}{{42}{2016}{{Silver et~al.}}{{}}}
\bibcite{Corrigibility}{{43}{2016}{{Soares et~al.}}{{}}}
\bibcite{Turing51}{{44}{1951}{{Turing}}{{}}}
\bibcite{Turner19a}{{45}{2019}{{Turner}}{{}}}
\bibcite{Turner19}{{46}{2019}{{Turner et~al.}}{{}}}
\bibcite{Turner20}{{47}{2020}{{Turner et~al.}}{{}}}
\bibcite{Wiki}{{48}{2022}{{Wikipedia}}{{}}}
\bibcite{wikiGoodhart}{{49}{2022}{{Wikipedia}}{{}}}
\bibcite{Yudkowsky13}{{50}{2013}{{Yudkowsky}}{{}}}
\bibcite{Yudkowsky16}{{51}{2016}{{Yudkowsky}}{{}}}
\bibstyle{apalike}
