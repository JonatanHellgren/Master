Only focusing on one objective can lead to major disruptions of the broader environment.
As agents are increasingly employed for real-world task, misspecification will become more difficult to avoid and will have more serious consequences.

side effect avoidance (Amodei et al) (Zhang et al)
minimizing change to the environment (Armstrong and Levinstein)
reachability preservation (Moldovan and Abbeel 2012, Eysenbach et al 2018)
Unified as _conservative agency_: optimizing the primary reward function while preserving the ability to optimize others.

Minimize side effects of misspecification.

[Amodei et al., 2016] explain:
An objective function that focuses on only one aspect of the environment may implicitly express indifference over other aspects of the environment. An agent optimizing this objective function might thus engage in major disruptions of the broader environment if doing so provides even a tiny advantage for the task at hand.

Assuming that there is one true objective function, we need the agent to "minimize regret for the correctly specified reward function over the course of the game"

"Inevitably, a reward misspecification might cause erroneous behavior, such as going to the wrong place. However, we would prefer misspecification not induce irreversible and costly mistakes, such as breaking expensive equipment or harming workers"

Costly mistakes decreases the agents ability to perform the one true objective, thus avoiding them should keep the true objective open even though a misspecification in the reward function.

"By preserving options for arbitrary objectives one can often preserve options for the correct objective - even without knowing anything about it."

Conservative agency: the unification of side effect avoidence, minimizing change to the state of the envoronment, and reachability preservation. "Optimizing the primary reward function while preserving the ability to optimize others."

"Everyday experience suggests that the ability to achieve one goal is linked to the ability to achieve a seemingly unrelated goal. Reading this paper takes away from time spent learning woodworking, and going hiking means you canâ€™t reach the airport as quickly. However, one might wonder whether these everyday intuitions are true in a formal sense. In other words, are the optimal value functions for a wide range of reward functions thus correlated? If so, preserving the ability to optimize somewhat unrelated reward functions likely preserves the ability to optimize the correct reward function"



