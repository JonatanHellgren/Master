This was a rather difficult paper to read through, due to all the definitions
and propositions. It took me a while to get the math and I had to read it a
couple of times before I felt that I some what got it. But it was nice, I
enyojed the experience and I learn some things that probably will be useful when
reading future papers. 

To summarise it very breifly the paper basically say that in the MDP setting 
some options have a higher propbabiliy of being optimal given that the rewards 
are randomly drawn from a distribution. The options that have higher probably
for being optimal also tend to give the agent a wider range of future possible
terminal states. That is to say that those options are instrumental for a higher
amount of possible terminal states.

The paper layed a good mathematical grounding which I might be able to use in
future simulations to check if the agents policy is optimal. Also the definition
of POWER might also be useful. 

