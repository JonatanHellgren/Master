Current approaches to penalizing side effects can introduce bad incentives.
Break down side effect penalties into two components: a baseline state and a measure of deviation fromthis baseline state. 

Maybe new headline: Penalizing side effects 

Aim is to avoid side effects without specifically defining what a side effect is. 

Most general approaches are reachability based methods. That either preserver reachability to the starting state or to another safe region. 
Faults with this is, they do not consider magnitude and some problems where a irreversible action is required becomes unsolvable.

Offsetting arises from choice of baseline and magnitude insensitivity arises from choice of deviance. 

attainable utulity measure generalizes the relative reachability.

Safety criteria are often implemented as constraints (3 refs). This approach works well if we know exactly what the agent must avoid, but is too inflexible for a general criterion for avoiding side effects. 

A more flexible way to implement a side effects criterion is by adding a penalty for imapcting the anvironment to the reward function, whuch acts as an instrinsic pseudo-reward. 

BASELINES
_Starting state baseline_
reservability-presering and safe exploration, the agent learns a reset policy.
Works well if the agent is the only source of change in environment, in dynamic enironments they also penalize irreversible transitions that are not caused by the agent. Thus it incentives the agent to prevent irreversible actions from occuring.

_Inaction baseline_
Compare with either the agent wasn't turned on or following a baseline policy such as the noop policy. 
This incentives offsetting. 

_Stepwise inaction baseline_
The same as the inaction baseline but it instead branches off the current state, instead of the initial state. Can include a rollout to also consider future side effects.

DEVIATION MEASURES
_Unreachability_
Natural choice is to use the difficulty of reaching the baseline state from the current state. This is used in safe exploration methods.
Promblems occur since it is a binary penalty, thus the agent becomes insensitive to the scale of the side effect.

_Relative reachability_
Is sensitive to the magnitude of the irreversible action. Based on how many states are reachable after action, not just the inital state.

_Attainable utility_
Also magnitude-sensitive. Observing that the informal notion of value may be richer then mere reachability of states, AU consders a set R of arbitrary reward functions.

_Value-diffence measures_
The general form of RR and AU
