# An Impact Measurement Manager Approach to AI Safety
This repository includes all files for my Master's thesis in Statistical Learning and AI. I have divided this repo into a report and a code part. The code part is probably the most relevant for anyone looking here. 



## Abstract
This thesis will begin with a thorough investigation of the current field of AI safety and answer questions such as why AI can become an issue, what the consequences are, and what we can do to prevent them. It then delves deeper into low-impact AIs. More specifically, side effect minimization through impact measurements. Lastly, this thesis will propose a novel impact measurement and evaluate it in a simulation study using an environment with different variations. 

The results of the simulation study are in line with other research. A correctly chosen impact measurement reduces side effects, and a too large impact measurement renders the agent unable to act. Besides this, the results showed increased performance in more complex environments. From this, we conclude that a more complex environment might suit this impact measurement better by putting more pressure on the agent, resulting in more intelligent behavior. 

## Results
Comming soon
